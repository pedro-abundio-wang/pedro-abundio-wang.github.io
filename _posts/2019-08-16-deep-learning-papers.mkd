---
layout: post
title:  "Deep Learning Papers"
date:   2019-08-16 01:00:00
categories: deep-learning
---

* TOC
{:toc}

## Algorithms

[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)

## CNN

[LeCun et al., 1998. Gradient-based learning applied to document recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)

Krizhevsky et al., 2012. ImageNet classification with deep convolutional neural networks

Simonyan & Zisserman 2015. Very deep convolutional networks for large-scale image recognition

He et al., 2015. Deep residual networks for image recognition

Lin et al., 2013. Network in network

Szegedy et al. 2014. Going deeper with convolutions

Fully Convolutional Networks for Semantic Segmentation

Sermanet et al., 2014, OverFeat: Integrated recognition, localization and detection using convolutional networks

Redmon et al., 2015, You Only Look Once: Unified real-time object detection

Girshik et. al, 2013, Rich feature hierarchies for accurate object detection and semantic segmentation

Girshik, 2015. Fast R-CNN

Ren et. al, 2016. Faster R-CNN: Towards real-time object detection with region proposal networks

Taigman et. al., 2014. DeepFace closing the gap to human level performance

Schroff et al.,2015, FaceNet: A unified embedding for face recognition and clustering

Visualizing and Understanding Convolutional Networks [https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf]

Gatys et al., 2015. A neural algorithm of artistic style. Images on slide generated by Justin Johnson

## RNN

Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches

Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling

Hochreiter & Schmidhuber 1997. Long short-term memory

van der Maaten and Hinton., 2008. Visualizing data using t-SNE

Mikolov et. al., 2013, Linguistic regularities in continuous space word representations

Bengio et. al., 2003, A neural probabilistic language model

Mikolov et. al., 2013. Efficient estimation of word representations in vector space.

Mikolov et. al., 2013. Distributed representation of words and phrases and their compositionality

Pennington et. al., 2014. GloVe: Global vectors for word representation

Bolukbasi et. al., 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings

Sutskever et al., 2014. Sequence to sequence learning with neural networks

Cho et al., 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation

Mao et. al., 2014. Deep captioning with multimodal recurrent neural networks

Vinyals et. al., 2014. Show and tell: Neural image caption generator

Karpathy and Li, 2015. Deep visual-semantic alignments for generating image descriptions

Papineni et. al., 2002. Bleu: A method for automatic evaluation of machine translation

Bahdanau et. al., 2014. Neural machine translation by jointly learning to align and translate

Xu et. al., 2015. Show, attend and tell: Neural image caption generation with visual attention

Graves et al., 2006. Connectionist Temporal Classification: Labeling unsegmented sequence data with recurrent neural networks

## GANs

Github: eriklindernoren/Keras-GAN

Szegedy et al. (2013): Intriguing properties of neural networks

Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy (2015): Explaining and harnessing adversarial examples [https://arxiv.org/pdf/1412.6572.pdf]

Generative Adversarial Nets [https://arxiv.org/pdf/1406.2661.pdf]

Conditional GAN [https://arxiv.org/pdf/1611.07004.pdf]

Super-Resolution GAN [https://arxiv.org/pdf/1609.04802.pdf]

CycleGAN [https://arxiv.org/pdf/1703.10593.pdf]

Alexey Kurakin, Ian J. Goodfellow, Samy Bengio (2017): Adversarial examples in the physical world

Lu et al. (2017): SafetyNet: Detecting and Rejecting Adversarial Examples Robustly

Harini Kannan et al. (2018): Adversarial Logit Pairing

Yuan et al. (2017): Adversarial Examples: Attacks and Defenses for Deep Learning]

Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas (2017): StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks

Ian Goodfellow (2014): NIPS Tutorial: GANs

Soumith et al. (2016): GanHacks

Lucic, Kurach et al. (2018): Are GANs Created Equal? A Large-Scale Study

Radford et al. (2015): UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS

Zhang et al. (2017): StackGAN++

Karras et al. (2018): A Style-Based Generator Architecture for Generative Adversarial Networks [https://www.youtube.com/watch?v=kSLJriaOumA&feature=youtu.be]

Zhu, Park et al. (2017): Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks

Shu Naritomi et al.: Face2Ramen

Takuya Tako: Face2Ramen using CycleGAN

Isola et al. (2017): Image-to-Image Translation with Conditional Adversarial Networks [https://affinelayer.com/pixsrv/ by Christopher Hesse] - [Pix2Pix]

Ledig et al. (2016): Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

Salimans et al. (2016): Improved Techniques for Training GANs

## Deep Reinforcement Learning

Silver, Schrittwieser, Simonyan et al. (2017): Mastering the game of Go without human knowledge

Mnih, Kavukcuoglu, Silver et al. (2015): Human Level Control through Deep Reinforcement Learning

Francisco S. Melo: Convergence of Q-learning: a simple proof

Video credits to Two minute papers: Google DeepMind's Deep Q-learning playing Atari Breakout [https://www.youtube.com/watch?v=V1eYniJ0Rnk]

Mnih, Kavukcuoglu, Silver et al. (2015): Human Level Control through Deep Reinforcement Learning

Credits: DeepMind, DQN Breakout [https://www.youtube.com/watch?v=TmPfTpjtdgg]

Ho et al. (2016): Generative Adversarial Imitation Learning

Schulman et al. (2017): Trust Region Policy Optimization

Schulman et al. (2017): Proximal Policy Optimization

Bansal et al. (2017): Emergent Complexity via multi-agent competition

OpenAI Blog: Competitive self-play

DeepMind Blog [https://deepmind.com/blog/alphago-zero-learning-scratch/]

Silver, Schrittwieser, Simonyan et al. (2017): Mastering the game of Go without human knowledge

Finn et al. (2017): Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks

Bellemare et al. (2017):Unifying Count-Based Exploration and Intrinsic Motivation

## Others

A guide to convolution arithmetic for deep learning

Is the deconvolution layer the same as a convolutional layer?

Deep Inside Convolutional Networks: Visualizing Image Classification Models and Saliency Maps

Understanding Neural Networks Through Deep Visualization

Learning Deep Features for Discriminative Localization [http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf]

Dropout: A Simple Way to Prevent Neural Networks from Overfitting [https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf]

DenseNet: Densely Connected Convolutional Networks

Human-level control through deep reinforcement learning [https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf]

Mastering the Game of Go without Human Knowledge [https://deepmind.com/documents/119/agz_unformatted_nature.pdf]

## CS230

[#001A Introduction to Deep Learning](http://datahacker.rs/001-introduction-to-deep-learning/)

[#001B Deep Learning, wait but why now?](http://datahacker.rs/001-introduction-to-deep-learning-2/)

[#002 Binary classification](http://datahacker.rs/binary-classification/)

[#002B Image representation in a computer](http://datahacker.rs/image-representation-in-a-computer/)

[#003A Logistic Regression – Cost Function Optimization](http://datahacker.rs/003-logistic-regression-cost-function-2/)

[#003B Gradient Descent](http://datahacker.rs/003b-gradient-descent/)

[#003C Gradient Descent in Python](http://datahacker.rs/003b-gradient-descent-in-python/)

[#004A Logistic Regression – The Computation Graph](http://datahacker.rs/004a-computation-graph/)

[#004B The Computation Graph – Example](http://datahacker.rs/004-computation-graph-2/)

[#005A Logistic Regression from scratch](http://datahacker.rs/005a_logistic-regression-from-scratch/)

[#005B Logistic Regression: Scratch vs. Scikit-Learn](http://datahacker.rs/logistic-regression-from-scratch-vs-scikit-learn/)

[#006A Fast Logistic Regression](http://datahacker.rs/006a-vectorizing-logistic-regression/)

[#006B Vectorization and Broadcasting in Python](http://datahacker.rs/006b-vectorization-optional/)

[#007 Neural Networks Representation](http://datahacker.rs/neural_networks_representation/)

[#008 Shallow Neural Network](http://datahacker.rs/shallow_neural_network/)

[#009 Activation functions and their derivatives](http://datahacker.rs/activation-functions-and-their-derivatives/)

[#010A Gradient Descent for Neural Networks](http://datahacker.rs/gradient-descent-for-neural-networks/)

[#010 B How to train a shallow Neural Network with a Gradient Desecent?](http://datahacker.rs/010-b-how-to-train-a-shallow-neural-network-with-a-gradient-desecent/)

[#010 C Random initialization of parameters in a Neural Network](http://datahacker.rs/random-initialization-of-parameters-in-neural-network/)

[#011 Deep L-layer Neural Network](http://datahacker.rs/deep-l-layer-neural-network/)

[#012A Building a Deep Neural Network](http://datahacker.rs/building-a-deep-neural-network/)

[#012 B Building a Deep Neural Network from scratch in Python](http://datahacker.rs/012-b-building-a-deep-neural-network-from-scratch-in-python/)

[#001 CNN Convolutional Neural Networks](http://datahacker.rs/001-cnn-convolutional-neural-networks/)

[#002 CNN Edge detection](http://datahacker.rs/002-cnn-edge-detection/)

[#003 CNN More On Edge Detection](http://datahacker.rs/003-cnn-more-on-edge-detection/)

[#004 CNN Padding](http://datahacker.rs/004-cnn-padding/)

[#005 CNN Strided Convolution](http://datahacker.rs/005-cnn-stried-convolution/)

[#006 CNN Convolution On RGB Images](http://datahacker.rs/006-cnn-convolution-on-rgb-images/)

[#007 CNN One Layer of A ConvNet ](http://datahacker.rs/007-cnn-one-layer-of-a-covolutional-neural-network/)

[#008 CNN An Example of A Convolutional Neural Network](http://datahacker.rs/008-cnn-an-example-of-a-convolutional-neural-network/)

[#009 CNN Pooling Layers](http://datahacker.rs/009-cnn-pooling-layers/)

[#010 CNN An Example of a Neural Network](http://datahacker.rs/010-cnn-an-example-of-a-neural-network/)

[#011 CNN Why convolutions](http://datahacker.rs/011-cnn-why-convolutions/)

[#012 CNN Convolutional Neural Networks – An Overview](http://datahacker.rs/0120-cnn-convolutional-neural-networks-an-overview/)

[#013 A CNN LeNet-5](http://datahacker.rs/013-cnn-latex-lenetenspace-enspace5/)

[#013 B CNN AlexNet](http://datahacker.rs/013-b-alexnet/)

[#013 C CNN VGG 16 and VGG 19](http://datahacker.rs/013-c-cnn-vgg-16-and-vgg-19/)

[#014 CNN Residual nets](http://datahacker.rs/014-cnn-residual-nets/)

[#015 CNN Why ResNets work](http://datahacker.rs/015-cnn-why-resnets-work/)

[#016 CNN Network in Network 1×1 Convolutions](http://datahacker.rs/016-cnn-network-in-network-1x1-convolutions/)

[#017 CNN Inception Network](http://datahacker.rs/017-inception-network/)

[#018 CNN Inception Network – Inception Module](http://datahacker.rs/018-cnn-inception-network/)

[#019 CNN Transfer Learning](http://datahacker.rs/019-cnn-transfer-learning/)

[#020 CNN Data Augmentation](http://datahacker.rs/020-cnn-data-augmentations/)

[#021 CNN Object Localization](http://datahacker.rs/021-object-localization/)

[#022 CNN Landmark Detection](http://datahacker.rs/022-cnn-landmark-detection/)

[#023 CNN Object Detection](http://datahacker.rs/023-cnn-object-detection/)

[#024 CNN Convolutional Operation of Sliding Windows](http://datahacker.rs/024-convolutional-operation-of-sliding-windows/)

[#025 CNN Bounding Box Predictions](http://datahacker.rs/025-cnn/)
